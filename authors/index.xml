<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Authors | NVIDIA Learning and Perception Research</title>
    <link>https://nvlabs.github.io/lpr/authors/</link>
      <atom:link href="https://nvlabs.github.io/lpr/authors/index.xml" rel="self" type="application/rss+xml" />
    <description>Authors</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://nvlabs.github.io/lpr/images/logo_hu2fe6632db44d28c9b9d53edd3914c1d6_112452_300x300_fit_lanczos_3.png</url>
      <title>Authors</title>
      <link>https://nvlabs.github.io/lpr/authors/</link>
    </image>
    
    <item>
      <title>LPR Group</title>
      <link>https://nvlabs.github.io/lpr/author/lpr-group/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://nvlabs.github.io/lpr/author/lpr-group/</guid>
      <description>&lt;h1 id=&#34;nvidia-learning-and-perception-research-group&#34;&gt;NVIDIA Learning and Perception Research Group&lt;/h1&gt;
&lt;p&gt;Welcome to the homepage of NVIDIA&amp;rsquo;s Learning and Perception Research group, led by &lt;a href=&#34;https://jankautz.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Jan Kautz&lt;/a&gt;. Our research spans computer vision and machine learning. We are particularly interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Human-centric Perception&lt;/em&gt;: body pose, hand pose, facial landmarks, gaze estimation, activity detection and recognition, etc.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Perception for Autonomous Machines&lt;/em&gt;: stereo, optical flow, object pose estimation, 3D shape estimation, etc.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Neural Content Capture and Synthesis&lt;/em&gt;: image and view synthesis, neural avatars, neural agents, denoising diffusion models, GANs, etc.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Resource-Efficient Deep Learning&lt;/em&gt;: pruning, NAS, efficient backbones, weakly- and self-supervised learning, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- (We are always looking for outstanding research scientist, please reach out to us if you are interested in joining our team.) --&gt;
&lt;p&gt;Graduate students interested in interning with us are welcome reach out directly to team members for more details.&lt;/p&gt;
&lt;!-- Please see [this link](https://nvidia.wd5.myworkdayjobs.com/NVIDIAExternalCareerSite) for open positions. --&gt;
&lt;!-- You can also contact our [members](#people) directly for potential internship positions. --&gt;
</description>
    </item>
    
  </channel>
</rss>
